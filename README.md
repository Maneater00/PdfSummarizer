🚀 **PDF Summarizer with Local LLM & RAG**  

I built a **privacy-focused** PDF summarization tool using a **local LLM with Retrieval-Augmented Generation (RAG)** to enhance accuracy and efficiency!  

### 🛠 **Tech Stack:**  
✅ **LangChain** – Orchestrates the LLM and retrieval process  
✅ **ChromaDB** – Vector database for efficient chunk retrieval  
✅ **PyPDF** – Extracts and preprocesses text from PDFs  
✅ **Gradio** – Provides an interactive UI for users to upload and summarize PDFs  

### 🔍 **How It Works:**  
1️⃣ **Text Extraction** – Parses PDFs using **PyPDF**  
2️⃣ **Chunking & Embeddings** – Splits text into smaller chunks & stores embeddings in **ChromaDB**  
3️⃣ **Retrieval** – Uses **vector search** to fetch the most relevant document parts  
4️⃣ **Summarization** – Generates concise, meaningful summaries using a **local LLM**  
5️⃣ **Interactive UI** – Simple **Gradio** interface for seamless user experience  

### 💡 **Key Learnings:**  
🚀 **RAG boosts accuracy** by retrieving only the most relevant content  
🔒 **Runs locally** for enhanced privacy—no external API calls required!  
